{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22056fc4-4b78-4408-a857-18682cdc5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be0286ea-9259-4672-8c5b-ced056bac8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5dad9a-bc82-4614-a7b7-47f9b28d83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f7f3d1-6243-449b-8a79-e59b892087ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                COMMENT_ID        AUTHOR                 DATE  \\\n",
      "144    z13osluqrpefv1hd323idhejzxanc3ai004   Tyrek Sings  2014-11-05T22:50:02   \n",
      "184  z131xnjjtqeyh5dy304cfhm50vagttfyemg0k   Chack Jason  2014-11-07T04:39:08   \n",
      "155  z12yinh5ks2oinqzn04cctkgvvrohbrazvo0k  Rancy Gaming  2014-11-06T09:41:07   \n",
      "79     z12ywjvgdtrhxdlz504cd1tquqvuhbs4abw         Angel  2014-11-02T17:27:09   \n",
      "4      z13fwbwp1oujthgqj04chlngpvzmtt3r3dw        GsMega  2013-11-10T16:05:38   \n",
      "\n",
      "                                               CONTENT  CLASS  \n",
      "144  CHECK MY CHANNEL OUT PLEASE. I DO SINGING COVERS﻿      1  \n",
      "184                                        OPPA &lt;3﻿      0  \n",
      "155  What free gift cards? Go here  http://www.swag...      1  \n",
      "79   Hi there~I'm group leader of Angel, a rookie K...      1  \n",
      "4              watch?v=vtaRGgvGtWQ   Check this out .﻿      1  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset/Youtube01-Psy.csv\")\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab1dbdd-cd69-43db-a471-6daef18a52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need only content and class cells for classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3096742-4b8e-489a-bfd8-0202e64576d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               CONTENT  CLASS\n",
      "75   if your like drones, plz subscribe to Kamal Ta...      1\n",
      "307  Go to my channel if u want to see a fly gettin...      1\n",
      "212                                Still the best. :D﻿      0\n",
      "258                     C'mon 3 billion views!!!!!!!!﻿      0\n",
      "110  EHI GUYS CAN YOU SUBSCRIBE IN MY CHANNEL? I AM...      1\n"
     ]
    }
   ],
   "source": [
    "data = data[[\"CONTENT\", \"CLASS\"]]\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd7799f-ac55-45aa-bbd1-52b9c6e5822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make the classes 0 as not spam and 1 as spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be3407b-5ed5-43c0-8ff0-da641ad18839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               CONTENT         CLASS\n",
      "163                         I found out this song now﻿      Not Spam\n",
      "183  The funny thing is, 1,700,000,000 of the views...      Not Spam\n",
      "115                                      #2012bitches﻿      Not Spam\n",
      "178  Please give us a chance and check out the new ...  Spam Comment\n",
      "90   https://www.indiegogo.com/projects/cleaning-th...  Spam Comment\n"
     ]
    }
   ],
   "source": [
    "data[\"CLASS\"] = data[\"CLASS\"].map({0: \"Not Spam\",\n",
    "                                   1: \"Spam Comment\"})\n",
    "print(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06c4fe14-20b5-4461-9616-bf965822bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff883915-ec4b-4a4d-a6d4-2c6012e61494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "x = np.array(data[\"CONTENT\"])\n",
    "y = np.array(data[\"CLASS\"])\n",
    "\n",
    "# CountVectozizer is used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text.\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "print(model.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b31d7a64-fa56-4175-b516-1deb751befec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets check out the model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ae9bb7-a94c-4749-9e94-a46c4ab8514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spam Comment']\n"
     ]
    }
   ],
   "source": [
    "sample = \"Check this out: https://thecleverprogrammer.com/\" \n",
    "data = cv.transform([sample]).toarray()\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d153798f-2aea-48b1-a886-ad6ed6d6ea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Spam']\n"
     ]
    }
   ],
   "source": [
    "sample = \"Lack of information!\" \n",
    "data = cv.transform([sample]).toarray()\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6701383b-7092-413e-8740-c20e25a4b05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count_vectorizer.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Naive Bayes model\n",
    "joblib.dump(model, 'spam_classifier_model.pkl')\n",
    "\n",
    "# Save the CountVectorizer object\n",
    "joblib.dump(cv, 'count_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379099b-af91-4165-9ac6-423f6ac2767f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
